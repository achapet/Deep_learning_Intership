{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import theano\n",
    "\n",
    "#Importing Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Data plotting\n",
    "from pandas.plotting import radviz\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "import pytoune\n",
    "from pytoune.framework import Model\n",
    "from pytoune.framework import callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0                                                UTR  \\\n",
      "0                0  AAAAAAAAAACATAATAACGATGATCAGTTAAAATCATAGTCTAAG...   \n",
      "1                1  AAAAAAAAAAGACTACAACAGATTGTAGTGGCGGACCAGTGTGCCT...   \n",
      "2                2  AAAAAAAAAATATGGGGCCCTGTTCCAAAGATACCTCAATTTCATA...   \n",
      "3                3  AAAAAAAAAATCTCTGGCCCGATTATACTGGAGCTAATGTAAAATT...   \n",
      "4                4  AAAAAAAAACATAAATATGAAGGCCTGACATTATAAATAACTTACC...   \n",
      "5                5  AAAAAAAAACGAAATCAAACAAGAGAAAAACTGCATAGTTCACTTA...   \n",
      "6                6  AAAAAAAAACGAATGAACGAGTAACAAAGGACCCCTAATAACTCGA...   \n",
      "7                7  AAAAAAAAACGGCAAACATAAGTAAGCGCTAAAACCTTTTATTGAA...   \n",
      "8                8  AAAAAAAAACGTTGCTATTATACCGAAGTCGCCCTAAAGCGTCCCT...   \n",
      "9                9  AAAAAAAAACTAATTCTGGAGCGACAAGTTTATACCCCATATTTTC...   \n",
      "10              10  AAAAAAAAACTCTGGTCGATCGAAGCTTTTTACTCGTCAACCACAA...   \n",
      "11              11  AAAAAAAAACTTGCATCCTACTGGAGGGTTAGGTACTAGACTTCTG...   \n",
      "12              12  AAAAAAAAATACGATGTGCCATACTAGATCGAAATTTGAACATGGA...   \n",
      "13              13  AAAAAAAAATATTTTCACTTTACTCGAGGACAATTATTCAACTGCC...   \n",
      "14              14  AAAAAAAAATCGTGCTGCCCAGATCTAGAGCAGTCCCTGTTGCCAT...   \n",
      "15              15  AAAAAAAACACAGTCCAGTCGAACACCATTCATCTAGGCGTTCATC...   \n",
      "16              16  AAAAAAAACATACAATTCCTAGAAGTCAAGAGATGGAGTTATAGCC...   \n",
      "17              17  AAAAAAAACGACATAACGGTTCAGGCGAAGACAAATCATTACCGCA...   \n",
      "18              18  AAAAAAAACGGGCGAGCCCGAGGAAGCGGCTTTTAATGAATATCTC...   \n",
      "19              19  AAAAAAAACGTAGATCGACCATGCTTTATCGTGCGGCTCTGAAATT...   \n",
      "20              20  AAAAAAAACGTGCCGGTATTTGACCGTACGGGACCCTTGCAGCTGT...   \n",
      "21              21  AAAAAAAACTAGCCGGAAGAGGCCTATCAGGTTCAGAGCACCGCCA...   \n",
      "22              22  AAAAAAAACTAGCCGTGATATTTTTTGTCGTCCGTGCGCCGTTGGG...   \n",
      "23              23  AAAAAAAACTCACAAATTAATCGTTCATTACGACGTTTCCCGCATG...   \n",
      "24              24  AAAAAAAACTCAGTTCGTTGTACGAGTTTTCTCTTCGAAGCGCTCA...   \n",
      "25              25  AAAAAAAACTGCACCTGGTTTTCAATCCTCCCGGATCTGTCAACGA...   \n",
      "26              26  AAAAAAAACTGCGCCTGGACTGACAAAAAGTTGCAACGCTGTCCCA...   \n",
      "27              27  AAAAAAAAGACGTAAAAGGTTTTTGACCTACACGATGAGTCTGGAC...   \n",
      "28              28  AAAAAAAAGATAACAGATAAGACGACTATTATCAAATTGACTTTAA...   \n",
      "29              29  AAAAAAAAGATCCGCCACGCACCGATTACCGGATAAACAAGCTTAT...   \n",
      "...            ...                                                ...   \n",
      "489318      489318  TTTTTTGTTCCTTAGTTATTAGTACAAGCGACATTCCCTAATTTAC...   \n",
      "489319      489319  TTTTTTTAAATATAACGAAGTGTACTAATCACCCATAAACCGCTAA...   \n",
      "489320      489320  TTTTTTTAACAACTCAGAATGCTAGGTATCTCAGTCGCAGGCCTAT...   \n",
      "489321      489321  TTTTTTTAAGGTGGCGGGAACGATAAGAATCGTACGACCACGCCGA...   \n",
      "489322      489322  TTTTTTTAATAGCCTCACGCACGTCTGCCGATATGCCTTCCCTAGA...   \n",
      "489323      489323  TTTTTTTACACGTCAAAGTGCGCTTTCTCTGTCTACCTACCGCCCA...   \n",
      "489324      489324  TTTTTTTACAGCTACGTCCAGCAACATAAATCTTTTCTTAAGACGC...   \n",
      "489325      489325  TTTTTTTAGCCTAAAATTGCGGCCGTCCGTACTTTGCACCACCCAT...   \n",
      "489326      489326  TTTTTTTAGTAGCGTCTCGTCCCTGCGAGGAGCCCGTGCTATATCA...   \n",
      "489327      489327  TTTTTTTATAACCGTCTACTTCGTCCTGCCCTACTAGCAAGTGTTC...   \n",
      "489328      489328  TTTTTTTATCAAATTGGACTAATTTTATTATAAAGCAGTGGTCTCG...   \n",
      "489329      489329  TTTTTTTATCAACGATCCCGACACTCTTGAAAGATATTGCCTTAAT...   \n",
      "489330      489330  TTTTTTTATTGAACTTCTACTTCCCGTACCTTCTTATCCAAACGCA...   \n",
      "489331      489331  TTTTTTTCACCAAACGTCCGCTGACCACGTCCGCACAGGCTGGCAT...   \n",
      "489332      489332  TTTTTTTCATTCATAGCCAATTAGTCACAGCAAGTGTCTCAGTTCT...   \n",
      "489333      489333  TTTTTTTCCCCTGCAGGTCTTACGGACCCGTGCCCCCTCGAAAACT...   \n",
      "489334      489334  TTTTTTTCCTTATAATCATTGAGTACACAAAGGGAACAGTGGCAGG...   \n",
      "489335      489335  TTTTTTTCGTGTAGTTCATGCCTCGAAACACCTCTGATAATAATTT...   \n",
      "489336      489336  TTTTTTTCTACATGTTCCCGTAGTTGGCGCGGTATGACGGAGAACT...   \n",
      "489337      489337  TTTTTTTCTGTTGAGCACTGGCTCATGAATCACCACGATATGGTTC...   \n",
      "489338      489338  TTTTTTTGATTCACCAGCTAAAGCTGACACCACTGACGTACAGAAA...   \n",
      "489339      489339  TTTTTTTGCACTGGAGCTCCTCACAACCGCCAAACCCCTAAGTTCC...   \n",
      "489340      489340  TTTTTTTGCGCGGTCTTGGGATGAACGCAACTCAGTGAGAAACTTC...   \n",
      "489341      489341  TTTTTTTGGCTAACGCGCATCATACTTCCCGAAAAGGTGGAGACCG...   \n",
      "489342      489342  TTTTTTTGTTAAACTTATTTCACGAAGTAAACGGGGGGAATGGCCC...   \n",
      "489343      489343  TTTTTTTGTTCCGAAGAGACCACTCAAACGTGAGCACGGCCAGACA...   \n",
      "489344      489344  TTTTTTTGTTCTCTCTTCAAAATCAGTCACCCCCAGTGCGTGCACT...   \n",
      "489345      489345  TTTTTTTTACAACCAGAGGATAGATTTAAGACGTCCGTCAGACCCG...   \n",
      "489346      489346  TTTTTTTTATAGCTGGTTGGTACCCCTGTATGGTCTTCCGACACGG...   \n",
      "489347      489347  TTTTTTTTCGGCATTTATGTAAGTGAGCTTGCGAAGACAAGCTACA...   \n",
      "\n",
      "        growth_rate   t0   t1  \n",
      "0         -1.237065   14    3  \n",
      "1          1.288663   14   49  \n",
      "2         -0.608457   13    6  \n",
      "3         -1.093964   12    3  \n",
      "4         -0.048841    7    6  \n",
      "5          0.822290   10   22  \n",
      "6         -1.013922    2    0  \n",
      "7         -0.104551   28   23  \n",
      "8          0.994061   57  143  \n",
      "9         -0.113760   49   40  \n",
      "10         1.470985   27  111  \n",
      "11         0.185787   46   51  \n",
      "12        -1.206294   39   10  \n",
      "13         1.293002   22   76  \n",
      "14        -3.093363   23    0  \n",
      "15         1.460833   98  391  \n",
      "16        -1.861220   55    7  \n",
      "17         0.025850   69   65  \n",
      "18         0.971994   13   33  \n",
      "19        -0.080824   58   49  \n",
      "20        -1.196243   17    4  \n",
      "21        -0.266707   26   18  \n",
      "22         0.235513   42   49  \n",
      "23        -0.183573   67   51  \n",
      "24         0.699876   19   36  \n",
      "25        -0.015393   20   18  \n",
      "26        -0.187954   87   66  \n",
      "27        -0.513146   19   10  \n",
      "28         1.447995   21   85  \n",
      "29         1.432764   19   76  \n",
      "...             ...  ...  ...  \n",
      "489318     1.065520    2    7  \n",
      "489319     1.789439   17   98  \n",
      "489320    -1.605599  102   18  \n",
      "489321    -1.994751   15    1  \n",
      "489322    -0.726240   17    7  \n",
      "489323     0.861219   45   99  \n",
      "489324     0.733667   80  154  \n",
      "489325     0.859063   64  140  \n",
      "489326     0.253026   59   70  \n",
      "489327     0.851946   51  111  \n",
      "489328    -1.787112   12    1  \n",
      "489329     0.984174   23   58  \n",
      "489330     0.526523    8   13  \n",
      "489331    -0.411746   45   27  \n",
      "489332     0.812929   13   28  \n",
      "489333     0.145315   15   16  \n",
      "489334     0.873148   24   54  \n",
      "489335     0.394846   21   29  \n",
      "489336    -1.707069   29    4  \n",
      "489337    -2.035573   24    2  \n",
      "489338    -0.163771   49   38  \n",
      "489339     0.135984   37   39  \n",
      "489340    -0.151698   18   14  \n",
      "489341    -0.278215   45   31  \n",
      "489342    -1.054744   24    7  \n",
      "489343     1.380601   80  295  \n",
      "489344     0.796187   26   54  \n",
      "489345     0.731318   10   20  \n",
      "489346    -0.944929   13    4  \n",
      "489347    -2.112534    8    0  \n",
      "\n",
      "[489348 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Buid the feature matrix\n",
    "data = pd.read_csv('/Users/almachapet--batlle/Documents/Internship U1001/2017---Deep-learning-yeast-UTRs-master/Data/Random_UTRs.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding of the sequences.\n",
    "\n",
    "i.e. we're converting the sequences from being represented as a 50 character string of bases to a 4x50 matrix of 1's and 0's, with each row corresponding to a base and every column a position in the UTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the work of Cuperus et al.\n",
    "# one hot encoding of UTRs\n",
    "# X = one hot encoding matrix\n",
    "# Y = growth rates\n",
    "\n",
    "def one_hot_encoding(df, seq_column, expression):\n",
    "\n",
    "    bases = ['A','C','G','T']\n",
    "    base_dict = dict(zip(bases,range(4))) # {'A' : 0, 'C' : 1, 'G' : 2, 'T' : 3}\n",
    "\n",
    "    n = len(df)\n",
    "    \n",
    "    # length of the UTR sequence\n",
    "    # we also add 10 empty spaces to either side\n",
    "    total_width = df[seq_column].str.len().max() + 20\n",
    "    \n",
    "    # initialize an empty numpy ndarray of the appropriate size\n",
    "    X = np.zeros((n, 1, 4, total_width))\n",
    "    \n",
    "    # an array with the sequences that we will one-hot encode\n",
    "    seqs = df[seq_column].values\n",
    "    \n",
    "    # loop through the array of sequences to create an array that keras will actually read\n",
    "    for i in range(n):\n",
    "        seq = seqs[i]\n",
    "        \n",
    "        # loop through each individual sequence, from the 5' to 3' end\n",
    "        for b in range(len(seq)):\n",
    "            # this will assign a 1 to the appropriate base and position for this UTR sequence\n",
    "            X[i, 0, base_dict[seq[b]], int(b + round((total_width - len(seq))/2.))] = 1.\n",
    "    \n",
    "        # keep track of where we are\n",
    "        if (i%10000)==0:\n",
    "            print(i),\n",
    "        \n",
    "    X = X.astype(theano.config.floatX)\n",
    "    Y = np.asarray(df[expression].values,\n",
    "                   dtype = theano.config.floatX)[:, np.newaxis]\n",
    "    \n",
    "    return X, Y, total_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n"
     ]
    }
   ],
   "source": [
    "X, Y, total_width = one_hot_encoding(data, 'UTR', 'growth_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]\n",
      "   [0. 0. 0. ... 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sorted numpy array of UTR indexes, from least reads to most reads\n",
    "sorted_inds = data.sort_values('t0').index.values\n",
    "\n",
    "\n",
    "train_inds = sorted_inds[:int(0.95*len(sorted_inds))] # 95% of the data as the training set\n",
    "\n",
    "\n",
    "test_inds = sorted_inds[int(0.95*len(sorted_inds)):] # UTRs with most reads at time point 0 as the test set\n",
    "\n",
    "# set the seed before randomly shuffling the data\n",
    "seed = 0.5\n",
    "random.shuffle(train_inds, lambda :seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Model\n",
    "\n",
    "I need to figure out how to make the dropout happen and Flatten. \n",
    "How do hidden units work in fully connected layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buid the neural network\n",
    "\n",
    "Try different structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(400, 128, kernel_size=[4, 13], stride=(1, 1))\n",
      "  (conv2): Conv2d(400, 16, kernel_size=[1, 13], stride=(1, 1))\n",
      "  (conv3): Conv2d(400, 16, kernel_size=[1, 13], stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=12, bias=True)\n",
      "  (lin_out1): Linear(in_features=120, out_features=400, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # input channel, output channels = number of filters, convolution kernel size\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(400, 128, [4,13])\n",
    "        self.conv2 = nn.Conv2d(400, 16, [1,13])\n",
    "        self.conv3 = nn.Conv2d(400, 16, [1,13])\n",
    "        self.fc1 = nn.Linear(400, 12)\n",
    "        self.lin_out1 = nn.Linear(120, 400)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.lol1(x)\n",
    "        x = nn.Dropout(p=0.15) #\n",
    "\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of optimizer & loss function => MSE \n",
    "# Using backpropagation\n",
    "\n",
    "# define model\n",
    "model = Net (10,2)\n",
    "\n",
    "# define loss function\n",
    "loss_func = nn.MSELoss() \n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "#Verification\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple time\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with PyToune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() got an unexpected keyword argument 'validation_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-b464492107a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m               \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m               \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m               \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearlyStopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m           )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eval() got an unexpected keyword argument 'validation_split'"
     ]
    }
   ],
   "source": [
    "num_features = 20\n",
    "num_epochs = 10\n",
    "num_train_samples = 800\n",
    "batch_size = 20\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "pytorch_module = torch.nn.Linear(num_features,1)\n",
    "optimizer = torch.optim.Adam(pytorch_module.parameters(), lr=1e-3)\n",
    "    \n",
    "model = Net()\n",
    "    \n",
    "# track model overfitting\n",
    "earlyStopping = pytoune.framework.EarlyStopping(monitor = 'val_loss',\n",
    "                                                  patience = 1,\n",
    "                                                  verbose = 0,\n",
    "                                                  mode = 'min')\n",
    "    \n",
    "# fit the model\n",
    "# note that I'm not passing the data to this function, I've just included it here (i.e. I've\n",
    "# included X and Y)\n",
    "model.eval(X[train_inds],\n",
    "              Y[train_inds],\n",
    "              validation_split = 0.2,\n",
    "              callbacks = [earlyStopping],\n",
    "          )\n",
    "    \n",
    "print ('MSE:',earlyStopping.best)\n",
    "return {'loss': earlyStopping.best, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions vs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
